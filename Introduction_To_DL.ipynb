{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Introduction_to_DL.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ni9dKYeS5Hgq",
        "bLFNyLnN7Emc",
        "AtcEkovs8J6E",
        "JxTZgoTk9Ii7",
        "kQhF11Wl9Yd6",
        "OyecAIq4-kJs",
        "pHMNcV2YAO2M",
        "MetjIi6UCiGI"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c50692d9e94f4558b462a1c089e846c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99ddd0a9b4834c27be409a726b89eb94",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06f209eb1e344c7087189ffae436b3dc",
              "IPY_MODEL_ca00b4dfd16a4356b6109824d1ab0a53"
            ]
          }
        },
        "99ddd0a9b4834c27be409a726b89eb94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06f209eb1e344c7087189ffae436b3dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_44b44d00c2884cecb6a7d79cd2012b19",
            "_dom_classes": [],
            "description": "  2%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 222208,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c7c166215a74046a6e0b8a1389c7221"
          }
        },
        "ca00b4dfd16a4356b6109824d1ab0a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ef66e9f6021d4f9a90e2e5e2e29bd316",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 222208/9912422 [00:06&lt;04:44, 34068.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49e1e5d4b8f449e9990d134048a1142a"
          }
        },
        "44b44d00c2884cecb6a7d79cd2012b19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c7c166215a74046a6e0b8a1389c7221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef66e9f6021d4f9a90e2e5e2e29bd316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49e1e5d4b8f449e9990d134048a1142a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YonDraco/learn-deep-learning/blob/main/Introduction_to_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC1TfEacFYfX"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33mmXnSOGAb1"
      },
      "source": [
        "Notebook này sẽ có hướng dẫn về các mô hình cơ bản và được sử dụng rộng rãi trong Deep Learning:\n",
        "\n",
        "\n",
        "*   Fully Connected Neural Network\n",
        "*   Convolution Neural Network (CNN)\n",
        "*   Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9lqWnC5zocz"
      },
      "source": [
        "## Fully Connected Neural Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCLOb0zOzmlb"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets \n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTKPbqIh0NfW"
      },
      "source": [
        "class MyFullyConnectedLayer(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    \"\"\"Class này sử dụng fully connected layer (hay còn gọi là dense layer)\n",
        " \n",
        "    Args:\n",
        "    input_dim: Số chiều đầu vào\n",
        "    output_dim: Số chiều đầu ra\n",
        "    \"\"\"\n",
        "    super(MyFullyConnectedLayer, self).__init__()\n",
        " \n",
        "    # Khởi tạo fully connected layer  \n",
        "    self.fc = nn.Linear(input_dim, output_dim)\n",
        "    # Khởi tạo activation function (ở đây sử dụng softmax)\n",
        "    self.activation = nn.Softmax(dim=1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    \"\"\"Đưa input qua fully connected layer và softmax để tính đầu ra\n",
        "    \"\"\"\n",
        "    # Đưa input qua fully connected layer\n",
        "    x = self.fc(x)\n",
        "    # Đưa qua softmax để tính score\n",
        "    x = self.activation(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6VlQ67I0W9o",
        "outputId": "0a10f7df-571d-4b0d-c967-025444ce57fc"
      },
      "source": [
        "# Khởi tạo mô hình neural network với \n",
        "# số chiều đầu vào là 128 và số chiều đầu ra là 3\n",
        "model = MyFullyConnectedLayer(input_dim=128, output_dim=3)\n",
        "# In ra model\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyFullyConnectedLayer(\n",
            "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
            "  (activation): Softmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTCs6h9d_1zZ",
        "outputId": "6edd8596-f5c7-4ac0-e087-54934f3e63b0"
      },
      "source": [
        "# Khởi tạo giá trị input ngẫu nhiên với 5 samples, mỗi sample có 128 chiều\n",
        "input_data = torch.randn(5, 128)\n",
        "# Đưa input qua mô hình\n",
        "out = model(input_data)\n",
        "# In ra kết quả\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3756, 0.5673, 0.0571],\n",
            "        [0.5371, 0.2178, 0.2451],\n",
            "        [0.1752, 0.3915, 0.4333],\n",
            "        [0.4233, 0.2065, 0.3702],\n",
            "        [0.5571, 0.2133, 0.2296]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TUNS7LhDsbo"
      },
      "source": [
        "## Multi layer Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIWwPR11AlvB"
      },
      "source": [
        "class MyFullyConnectedLayer(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    \"\"\"Class này xây dựng mô hình neural network với \n",
        "    1 input layer, 1 hidden layer và 1 output layer\n",
        "\n",
        "    Args:\n",
        "    input_dim: Số chiều đầu vào\n",
        "    hidden_dim: Số chiều tầng ẩn\n",
        "    output_dim: Số chiều đầu ra\n",
        "    \"\"\"\n",
        "    super(MyFullyConnectedLayer, self).__init__()\n",
        "\n",
        "    # Khởi tạo hidden layer với số chiều đầu vào bằng số  chiều của input\n",
        "    # và số chiều đầu ra bằng số chiều của tầng ẩn\n",
        "    self.hidden_layer = nn.Linear(input_dim, hidden_dim)\n",
        "    # Khởi tạo relu activation function\n",
        "    self.relu = nn.ReLU()\n",
        "    # Khởi tạo output layer với số chiều đầu vào bằng số chiều của tầng ẩn\n",
        "    # và số chiều đầu ra bằng số chiều của ouput\n",
        "    self.output = nn.Linear(hidden_dim, output_dim)\n",
        "    # Khởi tạo softmax activation function\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    \"\"\"Đưa input qua 1 tầng hidden layer để tính đầu ra\n",
        "    \"\"\"\n",
        "    # Đưa input qua 1 tầng hidden layer, số chiều của x là (input_dim, hidden_dim)\n",
        "    x = self.hidden_layer(x)\n",
        "    # Đưa qua relu \n",
        "    x = self.relu(x)\n",
        "    # Đưa qua output layer, số chiều của x là (hidden_dim, output_dim)\n",
        "    x = self.output(x)\n",
        "    # Tính softmax\n",
        "    x = self.softmax(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYve5ltoFRYJ",
        "outputId": "785c0d81-75a9-47dd-ea6f-3ab01a7835cf"
      },
      "source": [
        "# Khởi tạo mô hình \n",
        "model = MyFullyConnectedLayer(input_dim=128, hidden_dim=256, output_dim=3)\n",
        "# In ra model\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyFullyConnectedLayer(\n",
            "  (hidden_layer): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (output): Linear(in_features=256, out_features=3, bias=True)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6zRkFdIqrr0",
        "outputId": "d7436103-b50b-49dd-d677-383a473e870a"
      },
      "source": [
        "# Khởi tạo giá trị input ngẫu nhiên với 5 samples, mỗi sample có 128 chiều\n",
        "input_data = torch.randn(5, 128)\n",
        "# Đưa input qua mô hình\n",
        "out = model(input_data)\n",
        "# In ra kết quả\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.4119, 0.2537, 0.3344],\n",
            "        [0.3370, 0.3497, 0.3132],\n",
            "        [0.3611, 0.4051, 0.2338],\n",
            "        [0.3975, 0.3662, 0.2364],\n",
            "        [0.3010, 0.2695, 0.4296]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qDmwhjRH8Pu"
      },
      "source": [
        "## Training a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "c50692d9e94f4558b462a1c089e846c6",
            "99ddd0a9b4834c27be409a726b89eb94",
            "06f209eb1e344c7087189ffae436b3dc",
            "ca00b4dfd16a4356b6109824d1ab0a53",
            "44b44d00c2884cecb6a7d79cd2012b19",
            "6c7c166215a74046a6e0b8a1389c7221",
            "ef66e9f6021d4f9a90e2e5e2e29bd316",
            "49e1e5d4b8f449e9990d134048a1142a"
          ]
        },
        "id": "cI_zRvwQFWeJ",
        "outputId": "bb3e0269-095c-4b76-ec20-e1045d5262f0"
      },
      "source": [
        "# Hàm này dùng để đưa input về dạng Tensor và chuẩn hoá giá trị của ảnh về trong khoảng [0, 1]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)),])\n",
        "\n",
        "# Download MNIST dataset\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Chia data về từng batch có số lượng là 10\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c50692d9e94f4558b462a1c089e846c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aql0siCYIJTk"
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "  \"\"\"Xây dựng mô hình với 2 hidden layers và 1 output layer. \n",
        "  Sử dụng ReLU activation sau mỗi hidden layer.\n",
        "  Sử dụng Softmax activation để đưa kết quả về dưới dạng xác suất.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(MyModel,self).__init__()\n",
        "    self.hidden_1 = nn.Linear(28*28, 100) # (img_size, hidden_size_1) \n",
        "    self.hidden_2 = nn.Linear(100, 50) # (hidden_size_1, hidden_size_2)\n",
        "    self.output = nn.Linear(50, 10) # (hidden_size_2, num_output)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, img): \n",
        "    # Chuyển input dưới dạng ảnh 2 chiều (28, 28) thành vector 1 chiều (1, 28*28)\n",
        "    x = img.view(-1, 28*28)\n",
        "    # Đưa qua 1 tầng hidden layer và sử dụng relu \n",
        "    x = self.relu(self.hidden_1(x)) \n",
        "    x = self.relu(self.hidden_2(x))\n",
        "    # Đưa qua ouput layer và sử dụng softmax để đưa về xác suất\n",
        "    x = self.output(x)\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "    \n",
        "model = MyModel() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zCT2KiAMich",
        "outputId": "39d8003b-43e8-4d14-c1fb-443963c8e302"
      },
      "source": [
        "# Khởi tạo hàm loss, ở đây sử dụng Cross Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Khởi tạo hàm tối ưu Adam với learning_rate là 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# Khởi tạo số epoch\n",
        "epoch = 3\n",
        "\n",
        "# Bắt đầu training\n",
        "for epoch in range(epoch):\n",
        "    total_loss = 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Lấy input từ data_loader, \n",
        "        # thông tin gồm ma trận 2 chiều (28, 28) của ảnh đầu vào\n",
        "        # và giá trị label của ảnh\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Đưa đạo hàm về giá trị 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Đưa input qua mô hình\n",
        "        outputs = model(inputs)\n",
        "        # Tính loss giữa output của mô hình và labels chuẩn\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Tính toán đạo hàm\n",
        "        loss.backward()\n",
        "        # Cập nhật đạo hàm\n",
        "        optimizer.step()\n",
        "\n",
        "        # In ra giá trị loss\n",
        "        total_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # In ra hàm loss với mỗi 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, total_loss / 2000))\n",
        "            total_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.718\n",
            "[1,  4000] loss: 1.588\n",
            "[1,  6000] loss: 1.563\n",
            "[2,  2000] loss: 1.552\n",
            "[2,  4000] loss: 1.543\n",
            "[2,  6000] loss: 1.542\n",
            "[3,  2000] loss: 1.536\n",
            "[3,  4000] loss: 1.530\n",
            "[3,  6000] loss: 1.534\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ0BIq2uNX-a",
        "outputId": "b8a102e6-9916-425d-e459-788eac6c589a"
      },
      "source": [
        "# Số lượng đoán đúng\n",
        "correct = 0\n",
        "# Tổng số sample\n",
        "total = 0\n",
        "\n",
        "# Tính tỉ lệ mô hình dự đoán chính xác\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        x, y = data\n",
        "        output = model(x.view(-1, 28*28))\n",
        "        for idx, i in enumerate(output):\n",
        "            if torch.argmax(i) == y[idx]:\n",
        "                correct +=1\n",
        "            total +=1\n",
        "print(f'accuracy: {round(correct/total, 3)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "CIbsEaw8Qn5V",
        "outputId": "8e66c69e-b331-432b-e72e-29590f1de528"
      },
      "source": [
        "# Hiển thị hình ảnh và dự đoán\n",
        "plt.imshow(x[2].view(28, 28))\n",
        "plt.show()\n",
        "print(torch.argmax(model(x[2].view(-1, 28*28))[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8dd92562fec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Hiển thị hình ảnh và dự đoán\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IsiElfJfG8U"
      },
      "source": [
        "## Convolutional Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYgEvXbKRQ3O"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  \"\"\"Class này xây dựng mô hình CNN với 2 tầng convolution layers và max pooling ngay phía sau\n",
        "  Sau khi có feature map từ 2 tầng convolution, output sẽ tiếp tục đưa qua 2 tầng fully \n",
        "  connected layers và qua relu activation.\n",
        "  \"\"\"\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 6, 5) # 1 input channels, 6 output channels, kernel size = 5\n",
        "    self.pool = nn.MaxPool2d(2, 2) # kernel size = 2, stride = 2\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5) \n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120) # tầng fully connected thứ nhất\n",
        "    self.fc2 = nn.Linear(120, 84) # tầng fully connected thứ hai\n",
        "    self.fc3 = nn.Linear(84, 10) # tầng fully connected thứ ba, cũng là output layer\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x))) # đưa qua tầng conv thứ nhất\n",
        "    x = self.pool(F.relu(self.conv2(x))) # đưa qua tầng conv thứ hai\n",
        "    x = x.view(-1, 16 * 5 * 5) # đưa input từ dạng nhiều chiều thành 1 chiều\n",
        "    x = F.relu(self.fc1(x)) # đưa qua tầng fully connected thứ nhất\n",
        "    x = F.relu(self.fc2(x)) # đưa qua tầng fully connected thứ hai\n",
        "    x = self.fc3(x) # lấy output\n",
        "    return x\n",
        "cnn_model = CNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLyjHX7KgsH8",
        "outputId": "aa24988e-7619-4f93-b569-b341aa14a8fa"
      },
      "source": [
        "# Khởi tạo hàm loss, ở đây sử dụng Cross Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Khởi tạo hàm tối ưu Adam với learning_rate là 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# Khởi tạo số epoch\n",
        "epoch = 3\n",
        "\n",
        "# Bắt đầu training\n",
        "for epoch in range(epoch):\n",
        "    total_loss = 0.0\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Lấy input từ data_loader, \n",
        "        # thông tin gồm ma trận 2 chiều (28, 28) của ảnh đầu vào\n",
        "        # và giá trị label của ảnh\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Đưa đạo hàm về giá trị 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Đưa input qua mô hình\n",
        "        outputs = model(inputs)\n",
        "        # Tính loss giữa output của mô hình và labels chuẩn\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Tính toán đạo hàm\n",
        "        loss.backward()\n",
        "        # Cập nhật đạo hàm\n",
        "        optimizer.step()\n",
        "\n",
        "        # In ra giá trị loss\n",
        "        total_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # In ra hàm loss với mỗi 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, total_loss / 2000))\n",
        "            total_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 1.527\n",
            "[1,  4000] loss: 1.529\n",
            "[1,  6000] loss: 1.526\n",
            "[2,  2000] loss: 1.523\n",
            "[2,  4000] loss: 1.523\n",
            "[2,  6000] loss: 1.530\n",
            "[3,  2000] loss: 1.523\n",
            "[3,  4000] loss: 1.526\n",
            "[3,  6000] loss: 1.522\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_GVbvfPhJBQ",
        "outputId": "34fb984e-359e-4e3d-dd53-cb5c982e32e1"
      },
      "source": [
        "# Số lượng đoán đúng\n",
        "correct = 0\n",
        "# Tổng số sample\n",
        "total = 0\n",
        "\n",
        "# Tính tỉ lệ mô hình dự đoán chính xác\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        x, y = data\n",
        "        output = model(x.view(-1, 28*28))\n",
        "        for idx, i in enumerate(output):\n",
        "            if torch.argmax(i) == y[idx]:\n",
        "                correct +=1\n",
        "            total +=1\n",
        "print(f'accuracy: {round(correct/total, 3)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 0.942\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu5_9jL2hMGl",
        "outputId": "fe41348e-df4e-4514-ca4e-0ef9ff2983bc"
      },
      "source": [
        "# Hiển thị hình ảnh và dự đoán\n",
        "plt.imshow(x[0].view(28, 28))\n",
        "plt.show()\n",
        "print(torch.argmax(model(x[0].view(-1, 28*28))[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9PbPOcWiq1u"
      },
      "source": [
        "## RNN Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVSYmjIGtTSb"
      },
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import string\n",
        "import unicodedata\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnZj-XGE4-4W"
      },
      "source": [
        "### Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q63nBsS3tVj2"
      },
      "source": [
        "# donwload và extract data \n",
        "fileurl = \"https://download.pytorch.org/tutorial/data.zip\"\n",
        "r = requests.get(fileurl)\n",
        "open(\"data.zip\", 'wb').write(r.content)\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfTvtomK4B8a",
        "outputId": "fa4ac6ac-050b-43d5-cf01-9c48c58c4b4f"
      },
      "source": [
        "# data file\n",
        "filepath = \"data/names/\"\n",
        "\n",
        "# Khởi tạo list chứa names và labels tương ứng\n",
        "line_list = []\n",
        "category_list = []\n",
        "\n",
        "# Store categories \n",
        "all_categories = []\n",
        "\n",
        "# Loop over all files in the directory and read them\n",
        "for filename in os.listdir(filepath):   \n",
        "  lines = open(filepath+filename, encoding = \"utf-8\").read().strip().split(\"\\n\")\n",
        "  line_list += lines\n",
        "  category = filename.split(\".\")[0]\n",
        "  all_categories.append(category)\n",
        "  categories = [category]*len(lines)\n",
        "  category_list += categories\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "\n",
        "print(\"Length of line/category lists: {}/{}\".format(len(line_list), len(category_list)))\n",
        "print(\"Number of categories:\", n_categories)\n",
        "print(\"Categories:\", all_categories)\n",
        "print(\"First 5 names:\", line_list[0:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of line/category lists: 20074/20074\n",
            "Number of categories: 18\n",
            "Categories: ['Japanese', 'Vietnamese', 'Spanish', 'Arabic', 'French', 'Scottish', 'Polish', 'Russian', 'German', 'English', 'Italian', 'Czech', 'Dutch', 'Portuguese', 'Chinese', 'Irish', 'Greek', 'Korean']\n",
            "First 5 names: ['Abe', 'Abukara', 'Adachi', 'Aida', 'Aihara']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFurAdcz4hkb",
        "outputId": "3eb570d8-cfe4-4cd0-9a1a-a60e3fa2937c"
      },
      "source": [
        "# Số lượng names cho từng language\n",
        "unique, counts = np.unique(category_list, return_counts=True)\n",
        "print(\"Names per language in training data:\\n\", dict(zip(unique, counts)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Names per language in training data:\n",
            " {'Arabic': 2000, 'Chinese': 268, 'Czech': 519, 'Dutch': 297, 'English': 3668, 'French': 277, 'German': 724, 'Greek': 203, 'Irish': 232, 'Italian': 709, 'Japanese': 991, 'Korean': 94, 'Polish': 139, 'Portuguese': 74, 'Russian': 9408, 'Scottish': 100, 'Spanish': 298, 'Vietnamese': 73}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni9dKYeS5Hgq"
      },
      "source": [
        "### Convert names to tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTUOXggP4zTt",
        "outputId": "5bf1a866-2aa3-4082-d150-2b6351a9d33d"
      },
      "source": [
        "# Tạo bộ vocab cho letters\n",
        "all_letters = string.ascii_letters + \" .,;'-\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "print(\"Vocabulary:\", all_letters)\n",
        "print(\"Vocabulary size:\", n_letters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary: abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'-\n",
            "Vocabulary size: 58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geWtOjc55jID",
        "outputId": "18c2cf5d-f950-4440-9287-10abaeaa6d91"
      },
      "source": [
        "# Chuyển từ định dạng unicode sang ascii, loại bỏ các kí tự dấu\n",
        "def unicode_to_ascii(s):\n",
        "  return \"\".join(\n",
        "    c for c in unicodedata.normalize(\"NFD\", s)\n",
        "    if unicodedata.category(c) != \"Mn\"\n",
        "    and c in all_letters\n",
        "  )\n",
        "\n",
        "# Example\n",
        "print(\"Example: Ślusàrski >>>\", unicode_to_ascii(\"Ślusàrski\"))\n",
        "print(\"Example: Ngân >>>\", unicode_to_ascii(\"Ngân\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example: Ślusàrski >>> Slusarski\n",
            "Example: Ngân >>> Ngan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okmwH6mk5zga",
        "outputId": "a913d3d3-89f9-40f5-e513-09ca75924045"
      },
      "source": [
        "# Tìm giá trị index cho các letter\n",
        "def letter_to_index(letter):\n",
        "  return all_letters.find(letter)\n",
        "\n",
        "# Example\n",
        "print(\"Index of letter 'g':\", all_letters.find(\"g\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index of letter 'g': 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVFBK4fQ6Ed5",
        "outputId": "1d9fc012-6ee4-4879-dcfa-8379b13d5263"
      },
      "source": [
        "# Chuyển name thành dạng one-hot vector\n",
        "def line_to_tensor(line):\n",
        "  tensor = torch.zeros(len(line), 1, n_letters)\n",
        "  for i, letter in enumerate(line):\n",
        "    tensor[i][0][letter_to_index(letter)] = 1\n",
        "  return tensor\n",
        "\n",
        "# Chuyển toàn bộ data thành dạng ascii và one-hot vectors\n",
        "line_list_clean = [unicode_to_ascii(line) for line in line_list]\n",
        "line_list_tensorized = [line_to_tensor(line) for line in line_list_clean] \n",
        "\n",
        "# Example\n",
        "print(\"Example name: Ngan\")\n",
        "print(\"Tensor size:\", line_to_tensor(\"Ngan\").size())\n",
        "print(\"Tensorized name:\\n\", line_to_tensor(\"Ngan\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example name: Ngan\n",
            "Tensor size: torch.Size([4, 1, 58])\n",
            "Tensorized name:\n",
            " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLFNyLnN7Emc"
      },
      "source": [
        "### Sequence padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzzi55Mq61-x",
        "outputId": "1541b170-f3da-47e0-f1ad-4641685d7013"
      },
      "source": [
        "# tự động padding theo name có độ dài lớn nhất\n",
        "sequence_length = len(max(line_list, key=len))\n",
        "\n",
        "print(\"Longest name:\", max(line_list, key=len))\n",
        "print(\"Maximum sequence length:\", sequence_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest name: Shirinsky-Shikhmatov\n",
            "Maximum sequence length: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRmZ-PE87aAq",
        "outputId": "ebeeb5a4-fd69-4dad-8b26-2108db1873ee"
      },
      "source": [
        "# Pad sequences\n",
        "line_tensor = pad_sequence(line_list_tensorized)\n",
        "\n",
        "# Chuyển tensor thành format thích hợp cho bước sau: Number of observations, 1, sequence length, features\n",
        "line_tensor_permuted = line_tensor.permute(1,2,0,3)\n",
        "\n",
        "print(\"Original shape:\", line_tensor.size())\n",
        "print(\"Permuted shape:\", line_tensor_permuted.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original shape: torch.Size([20, 20074, 1, 58])\n",
            "Permuted shape: torch.Size([20074, 1, 20, 58])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtcEkovs8J6E"
      },
      "source": [
        "### Create NamesDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5IO57uS8DC3"
      },
      "source": [
        "# Chuyển tensor thành numpy array\n",
        "X = line_tensor_permuted.numpy()\n",
        "\n",
        "# Tạo dictionary để map các language thành dạng số\n",
        "category_dict = dict(zip(all_categories, range(n_categories)))\n",
        "\n",
        "# Chuyển toàn bộ label dạng text thành dạng số\n",
        "category_list_numeric = [category_dict.get(i) for i in category_list]\n",
        "y = np.array(category_list_numeric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f87WSDSv8tHk"
      },
      "source": [
        "class NamesDataset():\n",
        "  \"\"\"Tạo NamesDataset dùng để chứa thông tin về input và label\n",
        "  \"\"\"\n",
        "  def __init__(self, features, labels):\n",
        "    self.features = torch.from_numpy(features)\n",
        "    self.labels = torch.from_numpy(labels).type(torch.LongTensor)\n",
        "    self.len = len(features)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.features[index], self.labels[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "data_train = NamesDataset(features=X, labels=y)\n",
        "data_test = NamesDataset(features=X, labels=y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxTZgoTk9Ii7"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4mWJFtX88VO"
      },
      "source": [
        "# Batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Data loaders \n",
        "trainloader = DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True)\n",
        "testloader = DataLoader(dataset=data_test, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQhF11Wl9Yd6"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiUxmAhn9r75"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "    super(RNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)   # RNN\n",
        "    self.fc = nn.Linear(hidden_size, num_classes)  \n",
        "    self.softmax = nn.LogSoftmax(dim=1)   # Log softmax\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Khởi tạo inital hidden\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
        "    # Đưa input và h0 qua RNN\n",
        "    out, _ = self.rnn(x, h0)\n",
        "    # Lấy output từ hidden state cuối cùng\n",
        "    out = self.fc(out[:, -1, :])\n",
        "    # Log softmax output\n",
        "    out = self.softmax(out) \n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyecAIq4-kJs"
      },
      "source": [
        "### Training model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx4pyoSF9WAA",
        "outputId": "309c7008-697f-4668-9aa1-911c293a7e28"
      },
      "source": [
        "# Sử dụng GPU nếu có\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHpwLRuq9mRV"
      },
      "source": [
        "# Các parameters của mô hình\n",
        "input_size = n_letters   # size of vocabulary\n",
        "hidden_size = 128 # hidden dim\n",
        "num_layers = 2 # số hidden layer\n",
        "num_classes = n_categories # số lượng languages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq3O_xBe-iHN"
      },
      "source": [
        "# Khởi tạo mô hình\n",
        "model = RNN(input_size, hidden_size, num_layers, num_classes) \n",
        "\n",
        "# Gán mô hình với device (cpu hoặc gpu)\n",
        "model.to(device)\n",
        "\n",
        "# Traing hyper-parameters\n",
        "sequence_length = sequence_length   # length of padded tensors\n",
        "num_epochs = 50\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Print ra loss sau mỗi n step\n",
        "print_every = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD3rvc9y_INM",
        "outputId": "95079567-b2fd-4dc9-fd49-1955b1ba6c0a"
      },
      "source": [
        "# Bắt đầu training\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "print(\"Start of traing -- Device: {} -- Epochs: {} -- Batches: {} -- Batch size: {}\"\n",
        "      .format(device, num_epochs, len(trainloader), batch_size))\n",
        "\n",
        "# Khởi tạo các biến dùng để tính loss, accuracy và visualize\n",
        "running_loss = 0\n",
        "running_total = 0\n",
        "running_correct = 0\n",
        "loss_list = [] \n",
        "loss_list_print_every = [] \n",
        "\n",
        "# Đưa model về training mode\n",
        "model.train()\n",
        "\n",
        "# Train model\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (lines, labels) in enumerate(trainloader):\n",
        "        # Gán data vào device thính hợp\n",
        "        lines, labels = lines.to(device), labels.to(device)\n",
        "        \n",
        "        # Reshape batch cho phù hợp input của rnn\n",
        "        lines = lines.reshape(-1, sequence_length, input_size)\n",
        "        \n",
        "        # Forward and backward pass\n",
        "        output = model(lines)\n",
        "        loss = criterion(output, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Tính loss và accuracy\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        running_total += labels.size(0)\n",
        "        running_correct += (predicted == labels).sum().item()       \n",
        "        loss_list.append(loss.item())\n",
        "\n",
        "        # In ra loss và accuracy trung bình của mỗi mini-batch\n",
        "        if (i+1) % print_every == 0:         \n",
        "            print(\"Epoch: {}/{} -- Batches: {}/{} -- Training loss: {:.3f} -- Training accuracy: {:.3f}\"\n",
        "                  .format(epoch+1, num_epochs, i+1, len(trainloader), \n",
        "                          running_loss/print_every, running_correct/running_total))\n",
        "            \n",
        "            # Lưu running loss\n",
        "            loss_list_print_every.append(running_loss/print_every)\n",
        "            \n",
        "            # Reset running loss and accuracy\n",
        "            running_loss = 0\n",
        "            running_total = 0\n",
        "            running_correct = 0\n",
        "            \n",
        "print(\"Training complete. Total training time: {:.1f} seconds\".format(time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of traing -- Device: cuda -- Epochs: 50 -- Batches: 314 -- Batch size: 64\n",
            "Epoch: 1/50 -- Batches: 100/314 -- Training loss: 1.902 -- Training accuracy: 0.465\n",
            "Epoch: 1/50 -- Batches: 200/314 -- Training loss: 1.918 -- Training accuracy: 0.465\n",
            "Epoch: 1/50 -- Batches: 300/314 -- Training loss: 1.909 -- Training accuracy: 0.458\n",
            "Epoch: 2/50 -- Batches: 100/314 -- Training loss: 2.161 -- Training accuracy: 0.464\n",
            "Epoch: 2/50 -- Batches: 200/314 -- Training loss: 1.868 -- Training accuracy: 0.478\n",
            "Epoch: 2/50 -- Batches: 300/314 -- Training loss: 1.913 -- Training accuracy: 0.462\n",
            "Epoch: 3/50 -- Batches: 100/314 -- Training loss: 2.173 -- Training accuracy: 0.469\n",
            "Epoch: 3/50 -- Batches: 200/314 -- Training loss: 1.878 -- Training accuracy: 0.469\n",
            "Epoch: 3/50 -- Batches: 300/314 -- Training loss: 1.885 -- Training accuracy: 0.469\n",
            "Epoch: 4/50 -- Batches: 100/314 -- Training loss: 2.154 -- Training accuracy: 0.464\n",
            "Epoch: 4/50 -- Batches: 200/314 -- Training loss: 1.885 -- Training accuracy: 0.474\n",
            "Epoch: 4/50 -- Batches: 300/314 -- Training loss: 1.891 -- Training accuracy: 0.468\n",
            "Epoch: 5/50 -- Batches: 100/314 -- Training loss: 2.144 -- Training accuracy: 0.476\n",
            "Epoch: 5/50 -- Batches: 200/314 -- Training loss: 1.920 -- Training accuracy: 0.463\n",
            "Epoch: 5/50 -- Batches: 300/314 -- Training loss: 1.892 -- Training accuracy: 0.460\n",
            "Epoch: 6/50 -- Batches: 100/314 -- Training loss: 2.165 -- Training accuracy: 0.468\n",
            "Epoch: 6/50 -- Batches: 200/314 -- Training loss: 1.877 -- Training accuracy: 0.473\n",
            "Epoch: 6/50 -- Batches: 300/314 -- Training loss: 1.911 -- Training accuracy: 0.460\n",
            "Epoch: 7/50 -- Batches: 100/314 -- Training loss: 2.159 -- Training accuracy: 0.463\n",
            "Epoch: 7/50 -- Batches: 200/314 -- Training loss: 1.909 -- Training accuracy: 0.461\n",
            "Epoch: 7/50 -- Batches: 300/314 -- Training loss: 1.882 -- Training accuracy: 0.473\n",
            "Epoch: 8/50 -- Batches: 100/314 -- Training loss: 2.141 -- Training accuracy: 0.474\n",
            "Epoch: 8/50 -- Batches: 200/314 -- Training loss: 1.904 -- Training accuracy: 0.462\n",
            "Epoch: 8/50 -- Batches: 300/314 -- Training loss: 1.894 -- Training accuracy: 0.467\n",
            "Epoch: 9/50 -- Batches: 100/314 -- Training loss: 2.173 -- Training accuracy: 0.462\n",
            "Epoch: 9/50 -- Batches: 200/314 -- Training loss: 1.905 -- Training accuracy: 0.467\n",
            "Epoch: 9/50 -- Batches: 300/314 -- Training loss: 1.883 -- Training accuracy: 0.470\n",
            "Epoch: 10/50 -- Batches: 100/314 -- Training loss: 2.142 -- Training accuracy: 0.473\n",
            "Epoch: 10/50 -- Batches: 200/314 -- Training loss: 1.877 -- Training accuracy: 0.470\n",
            "Epoch: 10/50 -- Batches: 300/314 -- Training loss: 1.908 -- Training accuracy: 0.467\n",
            "Epoch: 11/50 -- Batches: 100/314 -- Training loss: 2.166 -- Training accuracy: 0.475\n",
            "Epoch: 11/50 -- Batches: 200/314 -- Training loss: 1.897 -- Training accuracy: 0.471\n",
            "Epoch: 11/50 -- Batches: 300/314 -- Training loss: 1.907 -- Training accuracy: 0.461\n",
            "Epoch: 12/50 -- Batches: 100/314 -- Training loss: 2.166 -- Training accuracy: 0.466\n",
            "Epoch: 12/50 -- Batches: 200/314 -- Training loss: 1.901 -- Training accuracy: 0.456\n",
            "Epoch: 12/50 -- Batches: 300/314 -- Training loss: 1.885 -- Training accuracy: 0.472\n",
            "Epoch: 13/50 -- Batches: 100/314 -- Training loss: 2.142 -- Training accuracy: 0.473\n",
            "Epoch: 13/50 -- Batches: 200/314 -- Training loss: 1.902 -- Training accuracy: 0.465\n",
            "Epoch: 13/50 -- Batches: 300/314 -- Training loss: 1.890 -- Training accuracy: 0.466\n",
            "Epoch: 14/50 -- Batches: 100/314 -- Training loss: 2.186 -- Training accuracy: 0.468\n",
            "Epoch: 14/50 -- Batches: 200/314 -- Training loss: 1.892 -- Training accuracy: 0.466\n",
            "Epoch: 14/50 -- Batches: 300/314 -- Training loss: 1.885 -- Training accuracy: 0.453\n",
            "Epoch: 15/50 -- Batches: 100/314 -- Training loss: 2.168 -- Training accuracy: 0.469\n",
            "Epoch: 15/50 -- Batches: 200/314 -- Training loss: 1.888 -- Training accuracy: 0.470\n",
            "Epoch: 15/50 -- Batches: 300/314 -- Training loss: 1.897 -- Training accuracy: 0.470\n",
            "Epoch: 16/50 -- Batches: 100/314 -- Training loss: 2.183 -- Training accuracy: 0.466\n",
            "Epoch: 16/50 -- Batches: 200/314 -- Training loss: 1.907 -- Training accuracy: 0.468\n",
            "Epoch: 16/50 -- Batches: 300/314 -- Training loss: 1.878 -- Training accuracy: 0.470\n",
            "Epoch: 17/50 -- Batches: 100/314 -- Training loss: 2.178 -- Training accuracy: 0.465\n",
            "Epoch: 17/50 -- Batches: 200/314 -- Training loss: 1.890 -- Training accuracy: 0.468\n",
            "Epoch: 17/50 -- Batches: 300/314 -- Training loss: 1.876 -- Training accuracy: 0.475\n",
            "Epoch: 18/50 -- Batches: 100/314 -- Training loss: 2.155 -- Training accuracy: 0.464\n",
            "Epoch: 18/50 -- Batches: 200/314 -- Training loss: 1.884 -- Training accuracy: 0.470\n",
            "Epoch: 18/50 -- Batches: 300/314 -- Training loss: 1.902 -- Training accuracy: 0.469\n",
            "Epoch: 19/50 -- Batches: 100/314 -- Training loss: 2.162 -- Training accuracy: 0.470\n",
            "Epoch: 19/50 -- Batches: 200/314 -- Training loss: 1.887 -- Training accuracy: 0.468\n",
            "Epoch: 19/50 -- Batches: 300/314 -- Training loss: 1.912 -- Training accuracy: 0.465\n",
            "Epoch: 20/50 -- Batches: 100/314 -- Training loss: 2.185 -- Training accuracy: 0.455\n",
            "Epoch: 20/50 -- Batches: 200/314 -- Training loss: 1.876 -- Training accuracy: 0.470\n",
            "Epoch: 20/50 -- Batches: 300/314 -- Training loss: 1.877 -- Training accuracy: 0.475\n",
            "Epoch: 21/50 -- Batches: 100/314 -- Training loss: 2.160 -- Training accuracy: 0.473\n",
            "Epoch: 21/50 -- Batches: 200/314 -- Training loss: 1.898 -- Training accuracy: 0.459\n",
            "Epoch: 21/50 -- Batches: 300/314 -- Training loss: 1.889 -- Training accuracy: 0.475\n",
            "Epoch: 22/50 -- Batches: 100/314 -- Training loss: 2.173 -- Training accuracy: 0.465\n",
            "Epoch: 22/50 -- Batches: 200/314 -- Training loss: 1.898 -- Training accuracy: 0.471\n",
            "Epoch: 22/50 -- Batches: 300/314 -- Training loss: 1.894 -- Training accuracy: 0.467\n",
            "Epoch: 23/50 -- Batches: 100/314 -- Training loss: 2.153 -- Training accuracy: 0.468\n",
            "Epoch: 23/50 -- Batches: 200/314 -- Training loss: 1.905 -- Training accuracy: 0.470\n",
            "Epoch: 23/50 -- Batches: 300/314 -- Training loss: 1.892 -- Training accuracy: 0.469\n",
            "Epoch: 24/50 -- Batches: 100/314 -- Training loss: 2.170 -- Training accuracy: 0.468\n",
            "Epoch: 24/50 -- Batches: 200/314 -- Training loss: 1.880 -- Training accuracy: 0.473\n",
            "Epoch: 24/50 -- Batches: 300/314 -- Training loss: 1.895 -- Training accuracy: 0.465\n",
            "Epoch: 25/50 -- Batches: 100/314 -- Training loss: 2.167 -- Training accuracy: 0.462\n",
            "Epoch: 25/50 -- Batches: 200/314 -- Training loss: 1.887 -- Training accuracy: 0.474\n",
            "Epoch: 25/50 -- Batches: 300/314 -- Training loss: 1.913 -- Training accuracy: 0.460\n",
            "Epoch: 26/50 -- Batches: 100/314 -- Training loss: 2.136 -- Training accuracy: 0.466\n",
            "Epoch: 26/50 -- Batches: 200/314 -- Training loss: 1.891 -- Training accuracy: 0.467\n",
            "Epoch: 26/50 -- Batches: 300/314 -- Training loss: 1.915 -- Training accuracy: 0.466\n",
            "Epoch: 27/50 -- Batches: 100/314 -- Training loss: 2.185 -- Training accuracy: 0.468\n",
            "Epoch: 27/50 -- Batches: 200/314 -- Training loss: 1.877 -- Training accuracy: 0.470\n",
            "Epoch: 27/50 -- Batches: 300/314 -- Training loss: 1.885 -- Training accuracy: 0.471\n",
            "Epoch: 28/50 -- Batches: 100/314 -- Training loss: 2.153 -- Training accuracy: 0.468\n",
            "Epoch: 28/50 -- Batches: 200/314 -- Training loss: 1.887 -- Training accuracy: 0.472\n",
            "Epoch: 28/50 -- Batches: 300/314 -- Training loss: 1.917 -- Training accuracy: 0.463\n",
            "Epoch: 29/50 -- Batches: 100/314 -- Training loss: 2.152 -- Training accuracy: 0.465\n",
            "Epoch: 29/50 -- Batches: 200/314 -- Training loss: 1.916 -- Training accuracy: 0.461\n",
            "Epoch: 29/50 -- Batches: 300/314 -- Training loss: 1.880 -- Training accuracy: 0.472\n",
            "Epoch: 30/50 -- Batches: 100/314 -- Training loss: 2.132 -- Training accuracy: 0.473\n",
            "Epoch: 30/50 -- Batches: 200/314 -- Training loss: 1.889 -- Training accuracy: 0.471\n",
            "Epoch: 30/50 -- Batches: 300/314 -- Training loss: 1.918 -- Training accuracy: 0.460\n",
            "Epoch: 31/50 -- Batches: 100/314 -- Training loss: 2.134 -- Training accuracy: 0.464\n",
            "Epoch: 31/50 -- Batches: 200/314 -- Training loss: 1.906 -- Training accuracy: 0.468\n",
            "Epoch: 31/50 -- Batches: 300/314 -- Training loss: 1.890 -- Training accuracy: 0.473\n",
            "Epoch: 32/50 -- Batches: 100/314 -- Training loss: 2.174 -- Training accuracy: 0.451\n",
            "Epoch: 32/50 -- Batches: 200/314 -- Training loss: 1.884 -- Training accuracy: 0.474\n",
            "Epoch: 32/50 -- Batches: 300/314 -- Training loss: 1.887 -- Training accuracy: 0.469\n",
            "Epoch: 33/50 -- Batches: 100/314 -- Training loss: 2.161 -- Training accuracy: 0.462\n",
            "Epoch: 33/50 -- Batches: 200/314 -- Training loss: 1.889 -- Training accuracy: 0.476\n",
            "Epoch: 33/50 -- Batches: 300/314 -- Training loss: 1.894 -- Training accuracy: 0.471\n",
            "Epoch: 34/50 -- Batches: 100/314 -- Training loss: 2.173 -- Training accuracy: 0.468\n",
            "Epoch: 34/50 -- Batches: 200/314 -- Training loss: 1.883 -- Training accuracy: 0.468\n",
            "Epoch: 34/50 -- Batches: 300/314 -- Training loss: 1.871 -- Training accuracy: 0.467\n",
            "Epoch: 35/50 -- Batches: 100/314 -- Training loss: 2.164 -- Training accuracy: 0.466\n",
            "Epoch: 35/50 -- Batches: 200/314 -- Training loss: 1.883 -- Training accuracy: 0.474\n",
            "Epoch: 35/50 -- Batches: 300/314 -- Training loss: 1.890 -- Training accuracy: 0.467\n",
            "Epoch: 36/50 -- Batches: 100/314 -- Training loss: 2.156 -- Training accuracy: 0.470\n",
            "Epoch: 36/50 -- Batches: 200/314 -- Training loss: 1.898 -- Training accuracy: 0.472\n",
            "Epoch: 36/50 -- Batches: 300/314 -- Training loss: 1.902 -- Training accuracy: 0.457\n",
            "Epoch: 37/50 -- Batches: 100/314 -- Training loss: 2.162 -- Training accuracy: 0.466\n",
            "Epoch: 37/50 -- Batches: 200/314 -- Training loss: 1.888 -- Training accuracy: 0.470\n",
            "Epoch: 37/50 -- Batches: 300/314 -- Training loss: 1.887 -- Training accuracy: 0.462\n",
            "Epoch: 38/50 -- Batches: 100/314 -- Training loss: 2.149 -- Training accuracy: 0.476\n",
            "Epoch: 38/50 -- Batches: 200/314 -- Training loss: 1.905 -- Training accuracy: 0.464\n",
            "Epoch: 38/50 -- Batches: 300/314 -- Training loss: 1.900 -- Training accuracy: 0.456\n",
            "Epoch: 39/50 -- Batches: 100/314 -- Training loss: 2.140 -- Training accuracy: 0.474\n",
            "Epoch: 39/50 -- Batches: 200/314 -- Training loss: 1.879 -- Training accuracy: 0.472\n",
            "Epoch: 39/50 -- Batches: 300/314 -- Training loss: 1.897 -- Training accuracy: 0.466\n",
            "Epoch: 40/50 -- Batches: 100/314 -- Training loss: 2.182 -- Training accuracy: 0.470\n",
            "Epoch: 40/50 -- Batches: 200/314 -- Training loss: 1.892 -- Training accuracy: 0.461\n",
            "Epoch: 40/50 -- Batches: 300/314 -- Training loss: 1.890 -- Training accuracy: 0.472\n",
            "Epoch: 41/50 -- Batches: 100/314 -- Training loss: 2.167 -- Training accuracy: 0.467\n",
            "Epoch: 41/50 -- Batches: 200/314 -- Training loss: 1.882 -- Training accuracy: 0.471\n",
            "Epoch: 41/50 -- Batches: 300/314 -- Training loss: 1.897 -- Training accuracy: 0.469\n",
            "Epoch: 42/50 -- Batches: 100/314 -- Training loss: 2.156 -- Training accuracy: 0.465\n",
            "Epoch: 42/50 -- Batches: 200/314 -- Training loss: 1.908 -- Training accuracy: 0.467\n",
            "Epoch: 42/50 -- Batches: 300/314 -- Training loss: 1.882 -- Training accuracy: 0.471\n",
            "Epoch: 43/50 -- Batches: 100/314 -- Training loss: 2.158 -- Training accuracy: 0.468\n",
            "Epoch: 43/50 -- Batches: 200/314 -- Training loss: 1.915 -- Training accuracy: 0.466\n",
            "Epoch: 43/50 -- Batches: 300/314 -- Training loss: 1.863 -- Training accuracy: 0.469\n",
            "Epoch: 44/50 -- Batches: 100/314 -- Training loss: 2.160 -- Training accuracy: 0.464\n",
            "Epoch: 44/50 -- Batches: 200/314 -- Training loss: 1.886 -- Training accuracy: 0.477\n",
            "Epoch: 44/50 -- Batches: 300/314 -- Training loss: 1.886 -- Training accuracy: 0.462\n",
            "Epoch: 45/50 -- Batches: 100/314 -- Training loss: 2.155 -- Training accuracy: 0.459\n",
            "Epoch: 45/50 -- Batches: 200/314 -- Training loss: 1.896 -- Training accuracy: 0.463\n",
            "Epoch: 45/50 -- Batches: 300/314 -- Training loss: 1.893 -- Training accuracy: 0.472\n",
            "Epoch: 46/50 -- Batches: 100/314 -- Training loss: 2.155 -- Training accuracy: 0.475\n",
            "Epoch: 46/50 -- Batches: 200/314 -- Training loss: 1.904 -- Training accuracy: 0.460\n",
            "Epoch: 46/50 -- Batches: 300/314 -- Training loss: 1.891 -- Training accuracy: 0.470\n",
            "Epoch: 47/50 -- Batches: 100/314 -- Training loss: 2.184 -- Training accuracy: 0.465\n",
            "Epoch: 47/50 -- Batches: 200/314 -- Training loss: 1.897 -- Training accuracy: 0.467\n",
            "Epoch: 47/50 -- Batches: 300/314 -- Training loss: 1.879 -- Training accuracy: 0.473\n",
            "Epoch: 48/50 -- Batches: 100/314 -- Training loss: 2.134 -- Training accuracy: 0.477\n",
            "Epoch: 48/50 -- Batches: 200/314 -- Training loss: 1.900 -- Training accuracy: 0.466\n",
            "Epoch: 48/50 -- Batches: 300/314 -- Training loss: 1.911 -- Training accuracy: 0.466\n",
            "Epoch: 49/50 -- Batches: 100/314 -- Training loss: 2.173 -- Training accuracy: 0.460\n",
            "Epoch: 49/50 -- Batches: 200/314 -- Training loss: 1.895 -- Training accuracy: 0.462\n",
            "Epoch: 49/50 -- Batches: 300/314 -- Training loss: 1.877 -- Training accuracy: 0.473\n",
            "Epoch: 50/50 -- Batches: 100/314 -- Training loss: 2.186 -- Training accuracy: 0.465\n",
            "Epoch: 50/50 -- Batches: 200/314 -- Training loss: 1.902 -- Training accuracy: 0.473\n",
            "Epoch: 50/50 -- Batches: 300/314 -- Training loss: 1.871 -- Training accuracy: 0.467\n",
            "Training complete. Total training time: 63.3 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHMNcV2YAO2M"
      },
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZYrpK6K_M_z",
        "outputId": "7def6d69-0c21-49a9-d207-f1f49189e88a"
      },
      "source": [
        "running_loss = 0\n",
        "labels_true = np.array([], dtype=int)\n",
        "labels_pred = np.array([], dtype=int)\n",
        "\n",
        "# Đưa model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():   # Không tính đạo hàm   \n",
        "    for i, (lines, labels) in enumerate(testloader):\n",
        "        lines, labels = lines.to(device), labels.to(device)\n",
        "        lines = lines.reshape(-1, sequence_length, input_size).to(device)\n",
        "        \n",
        "        # Đưa input vào model\n",
        "        output = model(lines)\n",
        "        loss = criterion(output, labels)\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)      \n",
        "\n",
        "        # Tính accuracy\n",
        "        labels_true = np.append(labels_true, labels.cpu().numpy())\n",
        "        labels_pred = np.append(labels_pred, predicted.cpu().numpy())\n",
        "\n",
        "        \n",
        "test_accuracy = np.equal(labels_pred, labels_true).mean()         \n",
        "        \n",
        "print(\"Evaluating network on {} images in test set -- Test loss: {:.3f} -- Test accuracy: {:.3f}\"\n",
        "      .format(len(testloader.dataset), running_loss/len(testloader), test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating network on 20074 images in test set -- Test loss: 1.917 -- Test accuracy: 0.469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MetjIi6UCiGI"
      },
      "source": [
        "### Accuracy per category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv1F4d1lClSe",
        "outputId": "a718ea79-aa58-4eca-ceeb-ffe1a4ed4acd"
      },
      "source": [
        "# Xây dựng ma trận 2 chiều rỗng để chứa kết quả\n",
        "cm = np.zeros((num_classes, num_classes))\n",
        "\n",
        "# Tạo confusion matrix\n",
        "for i in range(len(labels_true)):\n",
        "    cm[labels_true[i]][labels_pred[i]] +=1\n",
        "\n",
        "for i in range(num_classes):\n",
        "    cm[i] = cm[i] / cm[i].sum()\n",
        "\n",
        "print(\"Accuracy by category:\")\n",
        "acc_dict = dict(zip(all_categories, [round(i, 2) for i in (cm.diagonal())]))\n",
        "for i in range(len(acc_dict)):\n",
        "    print(list(acc_dict.keys())[i], \":\", list(acc_dict.values())[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy by category:\n",
            "Japanese : 0.0\n",
            "Vietnamese : 0.0\n",
            "Spanish : 0.0\n",
            "Arabic : 0.0\n",
            "French : 0.0\n",
            "Scottish : 0.0\n",
            "Polish : 0.0\n",
            "Russian : 1.0\n",
            "German : 0.0\n",
            "English : 0.0\n",
            "Italian : 0.0\n",
            "Czech : 0.0\n",
            "Dutch : 0.0\n",
            "Portuguese : 0.0\n",
            "Chinese : 0.0\n",
            "Irish : 0.0\n",
            "Greek : 0.0\n",
            "Korean : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgvzaobnCmI4"
      },
      "source": [
        "# Dự đoán một tên bất kì\n",
        "def predict(input_line, n_predictions=3):\n",
        "  input_tensorized = line_to_tensor(unicode_to_ascii(input_line))\n",
        "  num_zeros = sequence_length - len(input_line)\n",
        "  zeros = torch.zeros(num_zeros, 1, n_letters)\n",
        "  input_tensorized = torch.cat((input_tensorized, zeros), dim = 0)\n",
        "  input_tensorized = input_tensorized.permute(1,0,2)\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    input_tensorized = input_tensorized.to(device)\n",
        "    output = model(input_tensorized)\n",
        "    output = torch.exp(output)\n",
        "    topv, topi = output.topk(n_predictions)\n",
        "\n",
        "  print(\">\", input_line, \"\\nLanguage -- Class Probability\")\n",
        "  for i in range(n_predictions):\n",
        "    value = topv[0][i].item()\n",
        "    category_index = topi[0][i].item()\n",
        "    category = all_categories[category_index]\n",
        "    print(\"{} -- {:.2f}%\".format(category, value*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7P5OKrEGf-F",
        "outputId": "a0559fa1-0610-474a-8482-723aff8eeba2"
      },
      "source": [
        "test_name = \"Aguilera\"\n",
        "predict(test_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Aguilera \n",
            "Language -- Class Probability\n",
            "Russian -- 50.32%\n",
            "English -- 20.62%\n",
            "Arabic -- 9.22%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKeSjNKFGpJ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}